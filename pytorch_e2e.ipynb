{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APTOS_E2E.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyNKdKt2R3ou",
        "colab_type": "text"
      },
      "source": [
        "## End-2-End Pipeline from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgZVvBFCpb13",
        "colab_type": "text"
      },
      "source": [
        "?torch.tensor(label)\n",
        "?transforms.RandomResizedCrop(224),\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5mls9JRs_LHB",
        "colab": {}
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" --header=\"Cookie: _ga=GA1.3.723045802.1563092728\" --header=\"Connection: keep-alive\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/14774/536888/all.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1564818803&Signature=cGZ%2B9gUtXgqr0IAuP1dasVxTN1hm9EGqAz8XTLpJFBw92J%2FMacrdfarqVPtoWNPVc47zCMFXh8JO7OqpF03E%2BR7tWOqFk6SEH2mLvdgjKAaoq%2FPx4DLpqdC6CTh8YKqKKGJzZFcTZ5aFmocUgTTBhyaHfjOHoqR%2Fgo4JE663ixE1gSwciXCt%2BJjRNXqRL3drzKRRCDD1oM3xDuVBjHob5HboPoT2MCi08ZnkwkHId05abOSz%2FxnAMoyrsJSwGM5jsNF7LjzCETcqRQBkCwAWFJX46hnWzp3WBnN0uzOirqDt9FU7qH6HAkVa4Yhty%2Bd%2BHegB8Ae3KihQGMmotrh%2FlA%3D%3D&response-content-disposition=attachment%3B+filename%3Daptos2019-blindness-detection.zip\" -O \"aptos2019-blindness-detection.zip\" -c\n",
        "!unzip -q aptos2019-blindness-detection.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-OWJGaht6CX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm aptos2019-blindness-detection.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EgjAaW6d_LHF",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "mkdir test_images\n",
        "mkdir train_images\n",
        "unzip -q test_images.zip -d test_images\n",
        "unzip -q train_images.zip -d train_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWSGGrGnmf-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm train_images.zip\n",
        "!rm test_images.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FgT715Z4ywMn",
        "colab": {}
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" --header=\"Cookie: _ga=GA1.3.723045802.1563092728\" --header=\"Connection: keep-alive\" \"https://storage.googleapis.com/kaggle-datasets/27833/35481/pytorch-pretrained-models.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1564909775&Signature=RLj%2BFTlMVXG81iFn3Rt2cT6DeuGLxK%2BSVmQNPWMQEch66Yyca85uFfs4eF2fj5PuU6ACjtgIBcwRv2S2tMAlsibjQy4A7uWcMFf6r4kcm5GICgwIHvTUTUQrA9GGvpkXVAPIDIN4MTZk%2FQ0f1UBfJ6Eu%2FitKwfEh2%2F5HA0cftq0AKR%2F39IP5OOHVp7Bl7pdThjzpan%2B%2FviQltz6WuwuD0unWhu1JzT4GzeBC5XZBHWngrh7uPBcOMsf%2BcHG5ZNZll2HmXMzx4wECosTl7Yd3NUU16NFDZwFRTTmr2gE3J4vh5nUKc4Slkso0mmSKd1OvC5vyJK6DIIxHmZizFONiOA%3D%3D\" -O \"pytorch-pretrained-models.zip\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_fonZQVaPGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IJdCvqXkywMr",
        "colab": {}
      },
      "source": [
        "!unzip -q pytorch-pretrained-models.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpcGkNDfWv5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_frame.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Io2ee3_V3W0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Loading and Preprocessing:\n",
        "'''\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "'''\n",
        "import pandas as pd\n",
        "\n",
        "aptos_frame = pd.read_csv('train.csv')\n",
        "n = 65\n",
        "img_name = aptos_frame.iloc[n, 0] + '.png'\n",
        "label = aptos_frame.iloc[n,1]\n",
        "\n",
        "print('Image name: {}'.format(img_name))\n",
        "print('Label: {}'.format(label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pon11P1xV3T5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from skimage import io, transform\n",
        "\n",
        "def show_aptos(image, label):\n",
        "  \"\"\"Show image with label\"\"\"\n",
        "  plt.imshow(image)\n",
        "  #ax = plt.subplot()\n",
        "  plt.title('Label {}'.format(label))\n",
        "  #print('Label {}'.format(label))\n",
        "  plt.pause(0.001) #pause a bit so that plots are updated\n",
        "\n",
        "plt.figure()\n",
        "show_aptos(io.imread(os.path.join('train_images/', img_name)), label)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiepQ9d3Y6vU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataset Class:\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "class APTOSDataset(Dataset):\n",
        "  \"\"\"APTOS 2019 Blindness Detection Dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, csv_file, root_dir, transform=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        csv_file (string): Path to the csv file with labels.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    self.label_frame = pd.read_csv(csv_file)\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label_frame)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = os.path.join(self.root_dir, self.label_frame.iloc[idx, 0]) + '.png'\n",
        "    image = io.imread(img_name)\n",
        "    label = self.label_frame.iloc[idx, 1]\n",
        "    sample = {'image': image, 'label': label}\n",
        "\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "\n",
        "    return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY49sXroV3SV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aptos_dataset = APTOSDataset(csv_file='train.csv', root_dir='train_images/')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "for i in range(len(aptos_dataset)):\n",
        "    sample = aptos_dataset[i]\n",
        "\n",
        "    print(i, sample['image'].shape, sample['label'].shape)\n",
        "\n",
        "    ax = plt.subplot(1, 4, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title('Sample #{}'.format(i))\n",
        "    ax.axis('off')\n",
        "    show_aptos(**sample)\n",
        "\n",
        "    if i == 3:\n",
        "        plt.show()\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvVG3vxbdAza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Transforms\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Rescale(object):\n",
        "  \"\"\"Rescale the image in a sample to a given size.\n",
        "\n",
        "  Args:\n",
        "      output_size (tuple or int): Desired output size. If tuple, output is\n",
        "      matched to output_size. If int, smaller of image edges is matched to\n",
        "      output_size keeping aspect ratio the same.\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self,  output_size):\n",
        "    assert isinstance(output_size, (int, tuple))\n",
        "    self.output_size = output_size\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    image, label = sample['image'], sample['label']\n",
        "\n",
        "    h, w = image.shape[:2]\n",
        "    if isinstance(self.output_size, int):\n",
        "      if h > w:\n",
        "        new_h, new_w = self.output_size * h / w, self.output_size\n",
        "      else:\n",
        "        new_h, new_w = self.output_size, self.output_size * w / h\n",
        "\n",
        "    else:\n",
        "        new_h, new_w = self.output_size\n",
        "        \n",
        "    new_h, new_w = int(new_h), int(new_w)\n",
        "    \n",
        "    img = transform.resize(image, (new_h, new_w))\n",
        "    \n",
        "    # labels will have no effect\n",
        "    \n",
        "    return {'image' : img, 'label' : label}\n",
        "\n",
        "\n",
        "class RandomCrop(object):\n",
        "  \"\"\"Crop randomly the image in a sample\n",
        "\n",
        "  Args:\n",
        "      output_size (tuple or int): Desired output size. If int, square crop\n",
        "      is made.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, output_size):\n",
        "    assert isinstance(output_size, (int, tuple))\n",
        "    if isinstance(output_size, int):\n",
        "      self.output_size = (output_size, output_size)\n",
        "\n",
        "    else:\n",
        "      assert len(output_size) == 2\n",
        "      self.output_size = output_size\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    image, label = sample['image'], sample['label']\n",
        "    \n",
        "    h, w = image.shape[:2]\n",
        "    new_h, new_w = self.output_size\n",
        "\n",
        "    top = np.random.randint(0, h - new_h)\n",
        "    left = np.random.randint(0, w - new_w)\n",
        "    \n",
        "    image = image[top: top + new_h,\n",
        "                  left: left + new_w]\n",
        "\n",
        "    return {'image': image, 'label': label}\n",
        "\n",
        "class ToTensor(object):\n",
        "  \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "  def __call__(self, sample):\n",
        "    image, label = sample['image'], sample['label']\n",
        "\n",
        "    # swap color axis because\n",
        "    # numpy image: H x W x C\n",
        "    # torch image: C X H X W\n",
        "    image = image.transpose((2, 0, 1))\n",
        "\n",
        "    return {'image': torch.from_numpy(image),\n",
        "            'label': torch.tensor(label)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARBXbRC1dAvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compose Transforms\n",
        "scale = Rescale(256)\n",
        "crop = RandomCrop(224)\n",
        "composed = transforms.Compose([Rescale(256), RandomCrop(224)])\n",
        "\n",
        "# Apply each of the above transforms on sample.\n",
        "fig = plt.figure()\n",
        "sample = aptos_dataset[65]\n",
        "for i, tsfrm in enumerate([scale, crop, composed]):\n",
        "  transformed_sample = tsfrm(sample)\n",
        "\n",
        "  ax = plt.subplot(1, 3, i + 1)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title(type(tsfrm).__name__)\n",
        "  show_aptos(**transformed_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KUYqUwBdAtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# iterating through the dataset\n",
        "\n",
        "transformed_dataset = APTOSDataset(csv_file = 'train.csv',\n",
        "                                   root_dir = 'train_images/',\n",
        "                                   transform = transforms.Compose([\n",
        "                                                                   Rescale(256),\n",
        "                                                                   RandomCrop(224),\n",
        "                                                                   ToTensor()\n",
        "                                                                   ]))\n",
        "\n",
        "for i in range(len(transformed_dataset)):\n",
        "  sample = transformed_dataset[i]\n",
        "\n",
        "  print(i, sample['image'].size(), sample['label'].size())\n",
        "\n",
        "  if i == 3:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGTLmsrooc7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Batching the data\n",
        "Shuffling the data\n",
        "Load the data in parallel using multiprocessing workers\n",
        "\"\"\"\n",
        "dataloader = DataLoader(transformed_dataset, batch_size = 4,\n",
        "                        shuffle=True, num_workers=4)\n",
        "\n",
        "# Helper function to show a batch\n",
        "def show_aptos_batch(sample_batched):\n",
        "  \"\"\"Show image with label for a batch of samples.\"\"\"\n",
        "  images_batch, labels_batch = \\\n",
        "          sample_batched['image'], sample_batched['label']\n",
        "  batch_size = len(images_batch)\n",
        "  im_size = images_batch.size(2)\n",
        "  grid_border_size = 2\n",
        "\n",
        "  grid = utils.make_grid(images_batch)\n",
        "  plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "\n",
        "  for i in range(batch_size):\n",
        "    plt.title('Batch from dataloader')\n",
        "  \n",
        "\n",
        "for i_batch, sample_batched in enumerate(dataloader):\n",
        "  print(i_batch, sample_batched['image'].size(),\n",
        "        sample_batched['label'].size())\n",
        "  \n",
        "  # observe 4th batch and stop.\n",
        "  if i_batch == 3:\n",
        "    plt.figure()\n",
        "    show_aptos_batch(sample_batched)\n",
        "    plt.axis('off')\n",
        "    plt.ioff()\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6U82Su_oc3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transfer learning \n",
        "'''\n",
        "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "'''\n",
        "# License: BSD\n",
        "# Author: Sasank Chilamkurthy\n",
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-POkK5anujCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data augmentation and normalization for training\n",
        "# just normalization for validation\n",
        "\n",
        "data_transforms = {\n",
        "    'train' : transforms.Compose([\n",
        "        Rescale(256),\n",
        "        RandomCrop(224),\n",
        "        ToTensor()\n",
        "        #transforms.RandomResizedCrop(224),\n",
        "        #transforms.RandomHorizontalFlip(),\n",
        "        #transforms.ToTensor(),\n",
        "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val' : transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYCNHlSwui9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import sampler\n",
        "\n",
        "class ChunkSampler(sampler.Sampler):\n",
        "    \"\"\"Samples elements sequentially from some offset. \n",
        "    Arguments:\n",
        "        num_samples: # of desired datapoints\n",
        "        start: offset where we should start selecting from\n",
        "    \"\"\"\n",
        "    def __init__(self, num_samples, start = 0):\n",
        "        self.num_samples = num_samples\n",
        "        self.start = start\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.start + self.num_samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "  \n",
        "NUM_TRAIN = 2930\n",
        "NUM_VAL = 732\n",
        "\n",
        "dataset_sizes = {'train' : NUM_TRAIN, 'val' : NUM_VAL}\n",
        "\n",
        "train_dataset = APTOSDataset(csv_file = 'train.csv',\n",
        "                                   root_dir = 'train_images/',\n",
        "                                   transform = data_transforms['train'])\n",
        "\n",
        "val_dataset = APTOSDataset(csv_file = 'train.csv',\n",
        "                                   root_dir = 'train_images/',\n",
        "                                   transform = data_transforms['train'])\n",
        "\n",
        "image_datasets = {'train' : train_dataset, 'val' : val_dataset}\n",
        "\n",
        "loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=4, num_workers=4, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
        "\n",
        "loader_val = torch.utils.data.DataLoader(val_dataset, batch_size=4, num_workers=4, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
        "\n",
        "dataloaders = {'train' : loader_train, 'val' : loader_val}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydk4qB-kui71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "  \"\"\"Imshow for Tensor.\"\"\"\n",
        "  inp = inp.numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.299, 0.224, 0.225])\n",
        "  #inp = std*inp+mean\n",
        "  #inp = inp.clip(inp, 0, 1)\n",
        "  plt.imshow(inp)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.pause(0.001) # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "sample_batched = next(iter(dataloaders['train']))\n",
        "inputs = sample_batched['image']\n",
        "classes = sample_batched['label']\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[str(x) for x in classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAoPuu24ui6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Training the model\n",
        " # Scheduling the learning rate\n",
        " # Saving the best model\n",
        "'''\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "  since = time.time()\n",
        "\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        scheduler.step()\n",
        "        model.train() # set the model to training mode\n",
        "      else:\n",
        "        model.eval()\n",
        "\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "\n",
        "      # Iterate over data.\n",
        "      for sample_batched in dataloaders[phase]:\n",
        "        inputs = sample_batched['image'].to(device, dtype=torch.float)\n",
        "        labels = sample_batched['label'].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        # track history if only in train\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          loss = criterion(outputs, labels).cpu().numpy()\n",
        "\n",
        "          # backward + optimize only if in trianing phase\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        # statistics\n",
        "        running_loss += loss.items() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "      epoch_loss = running_loss / dataset_sizes[phase]\n",
        "      epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "      print('{}  Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "          phase, epoch_loss, epoch_acc))\n",
        "      \n",
        "      # deep copy the model\n",
        "      if phase == 'val' and epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    \n",
        "    print()\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print('Training complete in {:0f}m {:.0f}s'.format(\n",
        "      time_elapsed // 60, time_elapsed % 60))\n",
        "  print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "  # load the best model weights\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg3Ucq3Yui2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualize the model predicitons\n",
        "def visualize_model(model, num_images=6):\n",
        "  was_training = model.training\n",
        "  model.eval()\n",
        "  images_so_far = 0\n",
        "  fig = plt.figure()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, sample_batched in enumerate(dataloaders['val']):\n",
        "      inputs = sample_batched['image'].to(device)\n",
        "      labels = sample_batched['label'].to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "\n",
        "      for j in range(inputs.size()[0]):\n",
        "        images_so_far += 1\n",
        "        ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "        ax.axis('off')\n",
        "        ax.set_title('predicted: {}'.format(str(preds[j])))\n",
        "        imshow(inputs.cpu().data[j])\n",
        "\n",
        "        if images_so_far == num_images:\n",
        "          model.train(mode=was_training)\n",
        "          return\n",
        "    model.train(mode=was_training)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzT8LWJ5uizs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = models.resnet101(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(2048, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw3aw7E17hc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4ffYDy3WJC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing libraries needed\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from PIL import Image, ImageFile\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.optim import lr_scheduler\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8nULZX4WEM9F",
        "colab": {}
      },
      "source": [
        "#defining dataset class:\n",
        "'''\n",
        "1. Training Dataset\n",
        "2. Testing Dataset\n",
        "'''\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image, ImageFile\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class RetinopathyDatasetTrain(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file):\n",
        "\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join('train_images', self.data.loc[idx, 'id_code'] + '.png')\n",
        "        image = Image.open(img_name)\n",
        "        image = image.resize((256, 256), resample=Image.BILINEAR)\n",
        "        label = torch.tensor(self.data.loc[idx, 'diagnosis'])\n",
        "        return {'image': transforms.ToTensor()(image),\n",
        "                'labels': label\n",
        "                }\n",
        "\n",
        "\n",
        "class RetinopathyDatasetTest(Dataset):\n",
        "    def __init__(self, csv_file, transform):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join('test_images', self.data.loc[idx, 'id_code'] + '.png')\n",
        "        image = Image.open(img_name)\n",
        "        image = self.transform(image)\n",
        "        return {'image': image}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axCtyku1Q0dN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import sampler\n",
        "\n",
        "class ChunkSampler(sampler.Sampler):\n",
        "    \"\"\"Samples elements sequentially from some offset. \n",
        "    Arguments:\n",
        "        num_samples: # of desired datapoints\n",
        "        start: offset where we should start selecting from\n",
        "    \"\"\"\n",
        "    def __init__(self, num_samples, start = 0):\n",
        "        self.num_samples = num_samples\n",
        "        self.start = start\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.start + self.num_samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "      \n",
        "      \n",
        "NUM_TRAIN = 2930\n",
        "NUM_VAL = 732\n",
        "\n",
        "train_dataset = RetinopathyDatasetTrain(csv_file='train.csv')\n",
        "\n",
        "loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=16, num_workers=4, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
        "\n",
        "#val_dataset = RetinopathyDatasetTrain(csv_file='train.csv')\n",
        "\n",
        "loader_val = torch.utils.data.DataLoader(train_dataset, batch_size=16, num_workers=4, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
        "\n",
        "'''\n",
        "cifar10_train = dset.CIFAR10(PATH_TO_CIFAR, train=True, download=False,\n",
        "                           transform=T.ToTensor())\n",
        "loader_train = DataLoader(cifar10_train, batch_size=64, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
        "\n",
        "cifar10_val = dset.CIFAR10(PATH_TO_CIFAR, train=True, download=False,\n",
        "                           transform=T.ToTensor())\n",
        "loader_val = DataLoader(cifar10_val, batch_size=64, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
        "\n",
        "cifar10_test = dset.CIFAR10(PATH_TO_CIFAR, train=False, download=False,\n",
        "                          transform=T.ToTensor())\n",
        "loader_test = DataLoader(cifar10_test, batch_size=64)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSlPAq8ydUgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import *\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import *\n",
        "from PIL import Image\n",
        "from pandas import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSkuqzoGfM1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Irc4C-fVfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "for i in range(NUM_TRAIN):\n",
        "  sample = train_dataset[i]\n",
        "  \n",
        "  print(i, sample['image'].shape, sample['labels'].shape)\n",
        "  \n",
        "  if i == 3:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2hNoyVnfmnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "for i in range(NUM_TRAIN):\n",
        "  sample = train_dataset[i]\n",
        "  print(i, sample['image'].shape, sample['labels'].shape)\n",
        "  image = sample['image']\n",
        "  fig = plt.figure()\n",
        "  plt.imshow(np.transpose(image, (1, 2, 0))) \n",
        "\n",
        "  \n",
        "  if i == 3:\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X98YRutOmP-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    #img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(loader_train)\n",
        "sample = dataiter.next()\n",
        "images = sample['image']\n",
        "labels = sample['labels']\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % labels[j].numpy() for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTZiORcNcjjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#take a look at data:\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "dataiter = iter(loader_train)\n",
        "for i in range(20):\n",
        "  sample = dataiter.next()\n",
        "  images = sample['image']\n",
        "  labels = sample['labels']\n",
        "  ax = fig.add_subplot(2, 20//2, labels+1, xticks=[], yticks=[])\n",
        "  plt.imshow(images)\n",
        "  ax.set_title(f'Label: {labels}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgndL0WqRxlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for t, sample in enumerate(loader_train):\n",
        "  print(t, sample['image'].shape, sample['labels'].shape)\n",
        "  if t>5: break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvwhzhXfSZzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "face_dataset = RetinopathyDatasetTrain(csv_file='train.csv')\n",
        "\n",
        "\n",
        "for i in range(len(face_dataset)):\n",
        "    sample = face_dataset[i]\n",
        "\n",
        "    print(i, sample['image'].shape, sample['labels'].shape)\n",
        "    \n",
        "    if i == 3:\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gZBaU25KEM9J",
        "colab": {}
      },
      "source": [
        "model = torchvision.models.resnet101(pretrained=False)\n",
        "model.load_state_dict(torch.load(\"resnet101-5d3b4d8f.pth\"))\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(2048, 5)\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zkfrFgK2EM9M",
        "colab": {}
      },
      "source": [
        "plist = [\n",
        "         {'params': model.layer4.parameters(), 'lr': 1e-4, 'weight': 0.001},\n",
        "         {'params': model.fc.parameters(), 'lr': 1e-3}\n",
        "         ]\n",
        "\n",
        "optimizer = optim.Adam(plist, lr=0.001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=10)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouVVcfUaUZ-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "since = time.time()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "    scheduler.step()\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    tk0 = tqdm(loader_train, total=int(len(loader_train)))\n",
        "    counter = 0\n",
        "    for bi, d in enumerate(tk0):\n",
        "        inputs = d[\"image\"]\n",
        "        labels = d[\"labels\"]\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(True):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        counter += 1\n",
        "        tk0.set_postfix(loss=(running_loss / (counter * loader_train.batch_size)))\n",
        "    epoch_loss = running_loss / len(loader_train)\n",
        "    print('Training Loss: {:.4f}'.format(epoch_loss))\n",
        "\n",
        "time_elapsed = time.time() - since\n",
        "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "torch.save(model.state_dict(), \"model.bin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZFDNMf0oZJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "test_dataset = RetinopathyDatasetTest(csv_file='sample_submission.csv',\n",
        "                                      transform=test_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNFayMWiwHBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "model.eval()\n",
        "diagnosis = []\n",
        "with torch.no_grad():\n",
        "  tk0 = tqdm(test_data_loader, total=int(len(test_data_loader)))\n",
        "  for bi, d in enumerate(tk0):\n",
        "    inputs = d[\"image\"].to(device)\n",
        "    output = model(inputs)\n",
        "    pred = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
        "    for preds in pred:\n",
        "      diagnosis.append(preds)\n",
        "    #_, preds = output.data.cpu().max(1)\n",
        "    #preds = output.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)\n",
        "    #print(pred)\n",
        "    #pred = output.data.max(1, keepdim=True)[1].cpu().numpy().ravel().reshape(-1, 1)\n",
        "    #print(pred)\n",
        "    #diagnosis.append(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DOAeL5vwaJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(diagnosis)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UKLQUInyyjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = pd.read_csv('sample_submission.csv')\n",
        "sample.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO3zDQKey3N-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample.diagnosis = diagnosis\n",
        "sample.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5K51Zf9WI_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}